{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Problem 4. KNN (20 pts)\n",
    "1)\tImplement a basic KNN model on the yeast dataset. The task is to predict the compartment in a cell \n",
    "that a yeast protein will localize to base on the properties of its sequence. Do not use Scikit-learn.\n",
    "2)\tTo optimize the results, test with Manhattan and Euclidean distance metrics. \n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class KNN:\n",
    "\n",
    "    def __init__(self, k=3, distance_algo=\"euclidean\"):\n",
    "        self.distance_algo = distance_algo\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        predicted_labels = [self._predict(x) for x in X]\n",
    "        return np.array(predicted_labels)\n",
    "\n",
    "    def calc_euclidean_dist(self, x1, x2):\n",
    "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "    def calc_manhattan_dist(self, x1, x2):\n",
    "        return np.sum(np.absolute(x1 - x2))\n",
    "\n",
    "    def _predict(self, x):\n",
    "        distances_from_all_other_points = []\n",
    "        if (self.distance_algo == \"euclidean\"):\n",
    "            distances_from_all_other_points = [\n",
    "                self.calc_euclidean_dist(x, x_train) for x_train in self.X_train]\n",
    "        else:\n",
    "            distances_from_all_other_points = [\n",
    "                self.calc_manhattan_dist(x, x_train) for x_train in self.X_train]\n",
    "\n",
    "        # Taking only the most nearest k points to compare with\n",
    "        k_indices = np.argsort(distances_from_all_other_points)[:self.k]\n",
    "        neighbour_labels = [self.y_train[i] for i in k_indices]\n",
    "        votes = Counter(neighbour_labels).most_common(1)\n",
    "        return votes[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "total_data = genfromtxt('./yeast.data')\n",
    "total_data[:, 1:8][1:5]\n",
    "names = ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'label']\n",
    "df = pd.read_csv('./yeast.data', header=None,\n",
    "                 delim_whitespace=True, names=names)\n",
    "df['class_int'] = pd.Categorical(df['label']).codes\n",
    "y = np.array(df['class_int'])\n",
    "X = total_data[:, 1:8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data set into test and train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN on yeast dataset with euclidean distance for k = 3 is :  0.8254716981132075\n"
     ]
    }
   ],
   "source": [
    "classifier = KNN(3)\n",
    "classifier.fit(X, y)\n",
    "predictions = classifier.predict(X)\n",
    "acc = np.sum(predictions == y) / len(y)\n",
    "print(\"Accuracy of KNN on yeast dataset with euclidean distance for k = 3 is : \", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Euclidean metrics for k= 5  is :  0.5336322869955157\n",
      "Accuracy for Manhattan metrics for k= 5  is :  0.5358744394618834\n",
      "\n",
      "Accuracy for Euclidean metrics for k= 6  is :  0.5336322869955157\n",
      "Accuracy for Manhattan metrics for k= 6  is :  0.5493273542600897\n",
      "\n",
      "Accuracy for Euclidean metrics for k= 7  is :  0.547085201793722\n",
      "Accuracy for Manhattan metrics for k= 7  is :  0.5269058295964125\n",
      "\n",
      "Accuracy for Euclidean metrics for k= 8  is :  0.5582959641255605\n",
      "Accuracy for Manhattan metrics for k= 8  is :  0.5426008968609866\n",
      "\n",
      "Accuracy for Euclidean metrics for k= 9  is :  0.5381165919282511\n",
      "Accuracy for Manhattan metrics for k= 9  is :  0.5493273542600897\n",
      "\n",
      "Accuracy for Euclidean metrics for k= 10  is :  0.5605381165919282\n",
      "Accuracy for Manhattan metrics for k= 10  is :  0.5650224215246636\n",
      "\n",
      "Accuracy for Euclidean metrics for k= 11  is :  0.5426008968609866\n",
      "Accuracy for Manhattan metrics for k= 11  is :  0.5560538116591929\n",
      "\n",
      "Accuracy for Euclidean metrics for k= 12  is :  0.547085201793722\n",
      "Accuracy for Manhattan metrics for k= 12  is :  0.5582959641255605\n",
      "\n",
      "Accuracy for Euclidean metrics for k= 13  is :  0.5448430493273543\n",
      "Accuracy for Manhattan metrics for k= 13  is :  0.5448430493273543\n",
      "\n",
      "Accuracy for Euclidean metrics for k= 14  is :  0.5538116591928252\n",
      "Accuracy for Manhattan metrics for k= 14  is :  0.5448430493273543\n",
      "\n",
      "Accuracy for Euclidean metrics for k= 15  is :  0.5560538116591929\n",
      "Accuracy for Manhattan metrics for k= 15  is :  0.5403587443946188\n",
      "\n",
      "Accuracy for Euclidean metrics for k= 16  is :  0.5650224215246636\n",
      "Accuracy for Manhattan metrics for k= 16  is :  0.547085201793722\n",
      "\n",
      "Accuracy for Euclidean metrics for k= 17  is :  0.5650224215246636\n",
      "Accuracy for Manhattan metrics for k= 17  is :  0.5448430493273543\n",
      "\n",
      "Accuracy for Euclidean metrics for k= 18  is :  0.5560538116591929\n",
      "Accuracy for Manhattan metrics for k= 18  is :  0.5515695067264574\n",
      "\n",
      "Accuracy for Euclidean metrics for k= 19  is :  0.5493273542600897\n",
      "Accuracy for Manhattan metrics for k= 19  is :  0.5605381165919282\n",
      "\n",
      "Accuracy for Euclidean metrics for k= 20  is :  0.5762331838565022\n",
      "Accuracy for Manhattan metrics for k= 20  is :  0.5538116591928252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "3)\tReport the model's accuracy for both distance metrics with k values from 5 to 20. \n",
    "\"\"\"\n",
    "for i in range(5, 21):\n",
    "    knn_classifier_euclidean = KNN(i, distance_algo=\"euclidean\")\n",
    "    knn_classifier_euclidean.fit(X_train, y_train)\n",
    "    predictions_made_euclidean = knn_classifier_euclidean.predict(X_test)\n",
    "    accuracy_euclidean = np.sum(\n",
    "        predictions_made_euclidean == y_test) / len(y_test)\n",
    "\n",
    "    knn_classifier_manhattan = KNN(i, distance_algo=\"manhattan\")\n",
    "    knn_classifier_manhattan.fit(X_train, y_train)\n",
    "    predictions_made_manhattan = knn_classifier_manhattan.predict(X_test)\n",
    "    accuracy_manhattan = np.sum(\n",
    "        predictions_made_manhattan == y_test) / len(y_test)\n",
    "\n",
    "    print(\"Accuracy for Euclidean metrics for k=\",\n",
    "          i, \" is : \", accuracy_euclidean)\n",
    "    print(\"Accuracy for Manhattan metrics for k=\", i,\n",
    "          \" is : \", accuracy_manhattan, end=\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Problem 5. Gaussian Process (20 pts)\n",
    "1)\tConstruct Scikit-learn Gaussian Process models using basic, RBF, and Matern kernels. \n",
    "\"\"\"\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "column_names = ['s' + str(x) for x in range(1,33)]\n",
    "\n",
    "df = pd.read_csv('./wdbc.data', names=column_names)\n",
    "df_arr = np.asarray(df)\n",
    "x = pd.get_dummies(df['s2'])\n",
    "x = x.drop('B', axis=1)\n",
    "df['s2'] = x\n",
    "df.head()\n",
    "X = df.drop('s2',axis=1)\n",
    "y=df['s2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "      <th>s10</th>\n",
       "      <th>s11</th>\n",
       "      <th>...</th>\n",
       "      <th>s23</th>\n",
       "      <th>s24</th>\n",
       "      <th>s25</th>\n",
       "      <th>s26</th>\n",
       "      <th>s27</th>\n",
       "      <th>s28</th>\n",
       "      <th>s29</th>\n",
       "      <th>s30</th>\n",
       "      <th>s31</th>\n",
       "      <th>s32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           s1     s3     s4      s5      s6       s7       s8       s9  \\\n",
       "0      842302  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010   \n",
       "1      842517  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690   \n",
       "2    84300903  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740   \n",
       "3    84348301  11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140   \n",
       "4    84358402  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800   \n",
       "..        ...    ...    ...     ...     ...      ...      ...      ...   \n",
       "564    926424  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390   \n",
       "565    926682  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400   \n",
       "566    926954  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251   \n",
       "567    927241  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140   \n",
       "568     92751   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000   \n",
       "\n",
       "         s10     s11  ...     s23    s24     s25     s26      s27      s28  \\\n",
       "0    0.14710  0.2419  ...  25.380  17.33  184.60  2019.0  0.16220  0.66560   \n",
       "1    0.07017  0.1812  ...  24.990  23.41  158.80  1956.0  0.12380  0.18660   \n",
       "2    0.12790  0.2069  ...  23.570  25.53  152.50  1709.0  0.14440  0.42450   \n",
       "3    0.10520  0.2597  ...  14.910  26.50   98.87   567.7  0.20980  0.86630   \n",
       "4    0.10430  0.1809  ...  22.540  16.67  152.20  1575.0  0.13740  0.20500   \n",
       "..       ...     ...  ...     ...    ...     ...     ...      ...      ...   \n",
       "564  0.13890  0.1726  ...  25.450  26.40  166.10  2027.0  0.14100  0.21130   \n",
       "565  0.09791  0.1752  ...  23.690  38.25  155.00  1731.0  0.11660  0.19220   \n",
       "566  0.05302  0.1590  ...  18.980  34.12  126.70  1124.0  0.11390  0.30940   \n",
       "567  0.15200  0.2397  ...  25.740  39.42  184.60  1821.0  0.16500  0.86810   \n",
       "568  0.00000  0.1587  ...   9.456  30.37   59.16   268.6  0.08996  0.06444   \n",
       "\n",
       "        s29     s30     s31      s32  \n",
       "0    0.7119  0.2654  0.4601  0.11890  \n",
       "1    0.2416  0.1860  0.2750  0.08902  \n",
       "2    0.4504  0.2430  0.3613  0.08758  \n",
       "3    0.6869  0.2575  0.6638  0.17300  \n",
       "4    0.4000  0.1625  0.2364  0.07678  \n",
       "..      ...     ...     ...      ...  \n",
       "564  0.4107  0.2216  0.2060  0.07115  \n",
       "565  0.3215  0.1628  0.2572  0.06637  \n",
       "566  0.3403  0.1418  0.2218  0.07820  \n",
       "567  0.9387  0.2650  0.4087  0.12400  \n",
       "568  0.0000  0.0000  0.2871  0.07039  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold  ## Importing KFold Library\n",
    "kf = KFold(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import RBF, Matern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  [0.40350877 0.57017544 0.64912281 0.74561404 0.7699115 ]\n"
     ]
    }
   ],
   "source": [
    "# 2)\tImplement a 5-fold cross-validation algorithm to report the model and accuracy of each fold.\n",
    "# 3)\tReport the result. \n",
    "# RBF Kernel\n",
    "gau = GaussianProcessClassifier(kernel=RBF())\n",
    "from sklearn.model_selection import cross_val_score\n",
    "g_reg = cross_val_score(gau, X,y, scoring='accuracy', cv=kf)\n",
    "g_reg = abs(g_reg) \n",
    "print(\"Accuracy : \", g_reg) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :  [0.4122807  0.57894737 0.64912281 0.74561404 0.7699115 ]\n"
     ]
    }
   ],
   "source": [
    "# Matern Kernel\n",
    "gau = GaussianProcessClassifier(kernel=Matern())\n",
    "from sklearn.model_selection import cross_val_score\n",
    "g_reg = cross_val_score(gau, X,y, scoring='accuracy', cv=kf)\n",
    "g_reg = abs(g_reg) \n",
    "print(\"Accuracy is : \", g_reg)                      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is [0.40350877 0.57017544 0.64912281 0.74561404 0.7699115 ]\n"
     ]
    }
   ],
   "source": [
    "## Basic kernel\n",
    "gau = GaussianProcessClassifier() \n",
    "from sklearn.model_selection import cross_val_score\n",
    "g_reg = cross_val_score(gau, X,y, scoring='accuracy', cv=kf)\n",
    "g_reg = abs(g_reg)                       \n",
    "print(\"Accuracy is\", g_reg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b651bc0006b8767cec9813f263f504c408c124650dc129b07f5a761a4243485"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
